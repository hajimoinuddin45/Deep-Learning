import torch
import torchvision
from torchvision.transforms import functional as F
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from google.colab import files

# Load the pre-trained Faster R-CNN model
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# Define COCO object categories
COCO_INSTANCE_CATEGORY_NAMES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle',
    'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
    'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',
    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',
    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',
    'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 
    'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]

# Function to upload an image
def upload_image():
    uploaded = files.upload()
    for fn in uploaded.keys():
        return fn

# Function to perform object detection
def detect_objects(image_path, threshold=0.5, nms_threshold=0.3):
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_tensor = F.to_tensor(img_rgb).unsqueeze(0)
    
    with torch.no_grad():
        predictions = model(img_tensor)
    
    boxes = predictions[0]['boxes']
    scores = predictions[0]['scores']
    labels = predictions[0]['labels']
    
    # Apply Non-Maximum Suppression (NMS)
    indices = torchvision.ops.nms(boxes, scores, nms_threshold)
    
    filtered_predictions = []
    for idx in indices:
        if scores[idx] >= threshold:
            label_index = int(labels[idx])
            label_index = min(label_index, len(COCO_INSTANCE_CATEGORY_NAMES) - 1)
            filtered_predictions.append({
                'box': boxes[idx].tolist(),
                'label': COCO_INSTANCE_CATEGORY_NAMES[label_index],
                'score': scores[idx].item()
            })
    
    return filtered_predictions

# Function to get a color for each label
def get_color(label):
    colors = [(0, 255, 0), (0, 0, 255), (255, 0, 0), (0, 255, 255), (255, 255, 0), (255, 0, 255)]
    return colors[hash(label) % len(colors)]

# Function to count detected objects
def count_objects(detections):
    object_counts = {}
    for detection in detections:
        label = detection['label']
        if label in object_counts:
            object_counts[label] += 1
        else:
            object_counts[label] = 1
    return object_counts

# Upload image
image_path = upload_image()

# Perform object detection with adjustable thresholds
threshold = 0.5
nms_threshold = 0.3
detections = detect_objects(image_path, threshold, nms_threshold)

# Display results and save the image with detections
img = cv2.imread(image_path)
for detection in detections:
    print(f"Detected {detection['label']} with confidence {detection['score']:.2f} at {detection['box']}")
    x1, y1, x2, y2 = map(int, detection['box'])
    color = get_color(detection['label'])
    cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
    cv2.putText(img, detection['label'], (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

cv2_imshow(img)
cv2.imwrite('detected_objects.jpg', img)

# Print object counts
object_counts = count_objects(detections)
print("Object counts:", object_counts)
